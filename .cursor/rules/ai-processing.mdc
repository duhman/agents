---
description: OpenAI Assistants API for dynamic extraction and response generation with persistent reusable assistants and vector store retrieval
globs: apps/agent/**/*.ts, packages/prompts/**/*.ts, scripts/setup-assistants.ts
alwaysApply: false
---

# OpenAI Assistants API with Persistent Reusable Assistants

This rule documents the Assistants API architecture for email extraction and dynamic response generation using persistent reusable assistants created once and reused across all requests.

## Architecture Overview

The system uses **persistent reusable assistants** created once and reused across all requests:

1. **Extraction Assistant**: Analyzes emails and extracts structured cancellation data
2. **Response Assistant**: Generates dynamic, personalized customer responses
3. **Automatic RAG**: Both assistants automatically search the vector store via `file_search` tool
4. **Streaming Responses**: Response generation uses streaming for real-time output
5. **Thread Management**: Conversations managed via threads and runs
6. **Zero Cold Start Overhead**: Assistants created once, reused forever – no runtime creation cost

## Model Requirements

**CRITICAL: Always use `gpt-4.1` model for OpenAI Assistants**

- `gpt-4.1` is the ONLY model that supports Assistants API with file_search tool
- This model MUST be used in:
  - `scripts/setup-assistants.ts` - extraction and response assistant configs
  - Any dynamic assistant creation code
- Do NOT use: gpt-5-mini, gpt-4o-mini, or other models for assistants
- File_search tool only works with gpt-4.1 in Assistants API

Reference: https://platform.openai.com/docs/models/gpt-4.1

## Duplicate Prevention

**CRITICAL: Never create duplicate assistants in OpenAI account**

The setup script prevents duplicate creation by:

✅ **DO: Reuse persistent assistant IDs**

```bash
# Set environment variables from first run
export OPENAI_EXTRACTION_ASSISTANT_ID=asst_abc123...
export OPENAI_RESPONSE_ASSISTANT_ID=asst_xyz789...

# Subsequent runs UPDATE existing assistants
pnpm tsx scripts/setup-assistants.ts
```

❌ **DON'T: Run setup script without environment variables**

Running the script multiple times without IDs set will try to create new assistants.

**Assistant Lifecycle:**
1. First run: Creates extraction + response assistants → save IDs
2. Save IDs: Set `OPENAI_*_ASSISTANT_ID` environment variables
3. Reuse: Script checks for duplicates and updates instead of creating
4. Never: Duplicate assistants are created when IDs are set

**Key Pattern:**
```typescript
// Setup script checks by name to prevent duplicates
const existingAssistants = await openai.beta.assistants.list();
const duplicate = existingAssistants.data.find(a => a.name === config.name);

if (duplicate && !existingId) {
  throw new Error(`Assistant already exists: ${duplicate.id}`);
}
```

## Core Components

### 1. Setup Script (`scripts/setup-assistants.ts`)

Create persistent assistants programmatically with full control over model and tools:

```bash
# Run once to create assistants
pnpm tsx scripts/setup-assistants.ts

# Outputs:
# OPENAI_EXTRACTION_ASSISTANT_ID=asst_abc123...
# OPENAI_RESPONSE_ASSISTANT_ID=asst_xyz789...

# Save IDs to environment variables for reuse
```

**Key Features:**
- Creates both assistants with `gpt-4.1` model (required for Assistants API compatibility)
- Configures `file_search` tool with vector store
- Updates existing assistants if IDs provided (idempotent)
- Full control over temperature, instructions, and tools

### 2. Assistant Configuration (`assistant-config.ts`)

Configuration functions used **only by setup script**, not at runtime:

```typescript
/**
 * IMPORTANT: Used only by setup script to create/update assistants.
 * At runtime, use OPENAI_EXTRACTION_ASSISTANT_ID from environment.
 */
export function getExtractionAssistantConfig(): AssistantConfig {
  return {
    name: "Elaway Cancellation Extraction Assistant",
    model: "gpt-5-mini",  // Full model control via API
    temperature: 0,        // Deterministic
    tools: [{ type: "file_search" }],
    tool_resources: {
      file_search: {
        vector_store_ids: [process.env.OPENAI_VECTOR_STORE_ID!]
      }
    },
    instructions: `You are an expert email analyzer...`
  };
}
```

### 3. Assistants Processor (`assistants-processor.ts`)

Use environment variables directly – no creation logic:

```typescript
// Load persistent assistant IDs from environment
const extractionAssistantId = process.env.OPENAI_EXTRACTION_ASSISTANT_ID;
const responseAssistantId = process.env.OPENAI_RESPONSE_ASSISTANT_ID;

// Validate they exist
if (!extractionAssistantId || !responseAssistantId) {
  throw new Error(
    "Assistant IDs not configured. Run setup script: " +
    "pnpm --filter @agents/agent exec tsx scripts/setup-assistants.ts"
  );
}

async function extractWithAssistant(maskedEmail: string, logContext: LogContext): Promise<ExtractionResultEnhanced> {
  // Create thread with email
  const thread = await openai.beta.threads.create({
    messages: [{
      role: "user",
      content: `Analyze this customer email...\n\n${maskedEmail}`
    }]
  });

  // Run the PERSISTENT assistant
  const run = await openai.beta.threads.runs.createAndPoll(thread.id, {
    assistant_id: extractionAssistantId  // Reuse same assistant
  });

  // Process response...
}
```

## Best Practices

### Assistant Lifecycle

✅ **DO:** Create assistants once, reuse forever

```bash
# Once (via setup script)
pnpm tsx scripts/setup-assistants.ts
# OPENAI_EXTRACTION_ASSISTANT_ID=asst_abc...
# OPENAI_RESPONSE_ASSISTANT_ID=asst_xyz...

# Store IDs in environment
OPENAI_EXTRACTION_ASSISTANT_ID=asst_abc...
OPENAI_RESPONSE_ASSISTANT_ID=asst_xyz...

# Runtime: Always use the same assistants
const extractionAssistantId = process.env.OPENAI_EXTRACTION_ASSISTANT_ID;
```

❌ **DON'T:** Create assistants dynamically on each request

Creating assistants during request processing wastes API calls and loses performance history.

### Setup Script Usage

✅ **DO:** Use setup script to create or update assistants

```bash
# Create new assistants
pnpm tsx scripts/setup-assistants.ts

# Update existing assistants (provide IDs in .env)
export OPENAI_EXTRACTION_ASSISTANT_ID=asst_abc...
export OPENAI_RESPONSE_ASSISTANT_ID=asst_xyz...
pnpm tsx scripts/setup-assistants.ts
# Script updates them instead of creating new ones
```

❌ **DON'T:** Call config functions at runtime

```typescript
// ❌ WRONG: This is for setup only
const config = getExtractionAssistantConfig();
const assistant = await openai.beta.assistants.create(config);

// ✅ RIGHT: Use environment variable
const assistantId = process.env.OPENAI_EXTRACTION_ASSISTANT_ID;
```

### Vector Store Integration

✅ **DO:** Let assistants automatically search via file_search tool

```typescript
// Assistants API handles vector store search automatically
const assistant = await openai.beta.assistants.create({
  tools: [{ type: "file_search" }],
  tool_resources: {
    file_search: {
      vector_store_ids: [vectorStoreId]
    }
  }
});

// Assistant will use file_search during run.createAndPoll()
```

❌ **DON'T:** Manually fetch and inject vector store context

Vector store retrieval is handled automatically by the Assistants API file_search tool.

### Thread Management

✅ **DO:** Create new threads for each request

```typescript
const thread = await openai.beta.threads.create({
  messages: [{ role: "user", content: userMessage }]
});

const run = await openai.beta.threads.runs.createAndPoll(thread.id, {
  assistant_id: assistantId
});
```

❌ **DON'T:** Reuse threads across different requests

Each request should have its own thread for isolation and proper context management.

### Response Streaming

✅ **DO:** Use streaming for real-time response generation

```typescript
const stream = openai.beta.threads.runs.stream(thread.id, {
  assistant_id: assistantId
});

for await (const event of stream) {
  if (event.event === "thread.message.delta") {
    // Process streamed content
  }
}
```

❌ **DON'T:** Use createAndPoll() for response generation

Use streaming for better real-time performance and user experience.

### Temperature Settings

- **Extraction**: `temperature: 0` (deterministic, consistent output)
- **Response Generation**: `temperature: 0.3` (controlled creativity, personalization)

### Error Handling

✅ **DO:** Check run status and handle failures

```typescript
const run = await openai.beta.threads.runs.createAndPoll(thread.id, {
  assistant_id: assistantId
});

if (run.status !== "completed") {
  throw new Error(`Run failed with status: ${run.status}`);
}
```

❌ **DON'T:** Assume runs always complete successfully

Check status and handle failure cases appropriately.

## Processing Flow

```
Customer Email
    ↓
[PII Masking]
    ↓
[Load Persistent Assistants from Environment]
    ↓
[Extract with Assistants API]
  - Create thread
  - Run extraction assistant (reused)
  - Auto-search vector store via file_search
  - Parse JSON extraction
    ↓
[Validation]
  - Is cancellation?
  - Clear intent?
  - Sufficient data?
    ↓
[Create Ticket in Database]
    ↓
[Generate Response with Assistants API]
  - Create thread
  - Run response assistant (reused)
  - Stream response output
  - Auto-search vector store for similar cases
    ↓
[Save Draft and Metrics]
    ↓
[Post to Slack for Review]
```

## Configuration

### Environment Variables

```bash
# Required: Persistent assistant IDs from setup script
OPENAI_EXTRACTION_ASSISTANT_ID=asst_...
OPENAI_RESPONSE_ASSISTANT_ID=asst_...

# Required for setup script
OPENAI_API_KEY=sk-...
OPENAI_VECTOR_STORE_ID=vs_...
```

### Setup Workflow

1. **Run setup script once:**
   ```bash
   pnpm tsx scripts/setup-assistants.ts
   ```

2. **Save output IDs to environment:**
   ```bash
   OPENAI_EXTRACTION_ASSISTANT_ID=asst_abc123...
   OPENAI_RESPONSE_ASSISTANT_ID=asst_xyz789...
   ```

3. **Use in runtime (via env vars):**
   - No code changes needed
   - Assistants automatically loaded from environment
   - Same assistants used for all requests

4. **To update assistants:**
   - Modify instructions in `assistant-config.ts`
   - Re-run setup script with existing IDs
   - Script updates instead of creating new ones

## Performance Considerations

- **Zero Cold Start Overhead**: No assistant creation during request processing
- **Consistent Processing**: Same assistant ID for all requests enables OpenAI Dashboard tracking
- **Latency**: Assistants API + vector store search adds ~3-5 seconds per request
- **Cost**: Efficient – no wasted creation API calls
- **Reliability**: Automatic retry logic with exponential backoff (3 retries, 1s base delay)
- **Persistence**: Assistants persist in OpenAI Dashboard for lifetime tracking

## Monitoring & Metrics

Track these metrics:

```typescript
metricsCollector.record({
  extraction_method: "assistants-api",
  is_cancellation: extraction.is_cancellation,
  edge_case: extraction.edge_case,
  confidence,
  processing_time_ms: duration,
  policy_compliant: true,
  language: extraction.language,
  rag_context_used: true, // Always true with Assistants API
  has_payment_issue: extraction.has_payment_issue
});
```

**Benefits of Persistent Assistants:**
- Track performance over time via same assistant ID
- Identify patterns and improvements in OpenAI Dashboard
- Measure impact of instruction updates

## Testing

Test both assistants (IDs required in environment):

```typescript
// Validate configuration
it("should have assistant IDs configured", () => {
  expect(process.env.OPENAI_EXTRACTION_ASSISTANT_ID).toBeDefined();
  expect(process.env.OPENAI_RESPONSE_ASSISTANT_ID).toBeDefined();
});

// Test extraction
const extractionResult = await extractWithAssistant(maskedEmail, logContext);
expect(extractionResult.is_cancellation).toBe(true);
expect(extractionResult.reason).toBe("moving");

// Test response generation
const response = await generateResponseWithAssistant(extraction, maskedEmail, logContext);
expect(response.length).toBeGreaterThan(50);
expect(response.toLowerCase()).toContain("elaway");
```

## Troubleshooting

### Missing Assistant IDs

```
Error: OPENAI_EXTRACTION_ASSISTANT_ID environment variable is required.
Run: pnpm tsx scripts/setup-assistants.ts
```

**Solution:** Run setup script and save IDs to environment variables.

### Run fails with status "requires_action"

The assistant encountered a tool call (file_search) that needs to be handled:

```typescript
if (run.status === "requires_action") {
  // Submit tool results and continue polling
  // (handled automatically by createAndPoll)
}
```

### No JSON in extraction response

Ensure the extraction assistant instructions explicitly request JSON output and include proper formatting examples.

### Vector store searches returning no results

Check that:
1. Vector store ID is correct
2. Files are properly uploaded and indexed
3. Query is specific enough for semantic matching
4. File chunks contain relevant content

## References

- `scripts/setup-assistants.ts` - Setup script for creating/updating assistants
- `apps/agent/src/assistant-config.ts` - Assistant configurations (setup only)
- `apps/agent/src/assistants-processor.ts` - Main processor implementation
- `apps/agent/src/tests/assistants-processor.test.ts` - Comprehensive tests
- `README.md` - Initial setup instructions
- OpenAI Assistants API: https://platform.openai.com/docs/assistants
- Vector Stores: https://platform.openai.com/docs/assistants/tools/file-search
